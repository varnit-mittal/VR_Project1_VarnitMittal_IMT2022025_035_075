{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification with CNN vs. ML Classifiers\n",
    "\n",
    "This notebook demonstrates how to design, train, and evaluate a Convolutional Neural Network (CNN) to classify images as **with mask** or **without mask**. We also explore hyperparameter variations (learning rate, batch size, optimizer, and activation function) and finally compare the CNN's performance with traditional ML classifiers using handcrafted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varni\\miniconda3\\envs\\myenv\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.5 when it was built against 1.14.2, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing\n",
    "\n",
    "We assume your dataset is organized into two folders: one for images **with mask** and another for images **without mask**. We load the images in color, resize them to 64x64, and normalize pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unable to read ./dataset/with_mask\\0_0_œ¬‘ÿ.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-23 132115.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-23 132400.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-24 171804.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-24 172039.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-24 202509.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-24 205216.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-24 215234.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-24 215615.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-24 220536.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-24 222124.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-24 224833.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-24 225329.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-24 225427.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-25 150422.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-25 150847.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-25 150921.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-25 185823.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\0_0_≈˙◊¢ 2020-02-25 190026.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\1_0_≈˙◊¢ 2020-02-24 202935.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\1_0_≈˙◊¢ 2020-02-24 215624.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\1_0_≈˙◊¢ 2020-02-24 224914.png. Skipping...\n",
      "Warning: Unable to read ./dataset/with_mask\\1_0_≈˙◊¢ 2020-02-25 151918.png. Skipping...\n",
      "Loaded 2142 images with mask and 1930 images without mask.\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_folder(folder, label, image_size=(64, 64)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)  # Load in color\n",
    "        if img is None:\n",
    "            print(f\"Warning: Unable to read {img_path}. Skipping...\")\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        img = cv2.resize(img, image_size)\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Update these paths to point to your dataset folders\n",
    "mask_folder = \"./dataset/with_mask\"\n",
    "no_mask_folder = \"./dataset/without_mask\"\n",
    "\n",
    "mask_images, mask_labels = load_images_from_folder(mask_folder, label=1)\n",
    "no_mask_images, no_mask_labels = load_images_from_folder(no_mask_folder, label=0)\n",
    "\n",
    "print(f\"Loaded {len(mask_images)} images with mask and {len(no_mask_images)} images without mask.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 4072\n",
      "Image shape: (64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "# Combine the data\n",
    "X = np.array(mask_images + no_mask_images)\n",
    "y = np.array(mask_labels + no_mask_labels)\n",
    "\n",
    "# Normalize pixel values\n",
    "X = X.astype('float32') / 255.0\n",
    "\n",
    "print('Total images:', X.shape[0])\n",
    "print('Image shape:', X.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3257\n",
      "Testing set size: 815\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print('Training set size:', X_train.shape[0])\n",
    "print('Testing set size:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the CNN Model\n",
    "\n",
    "We create a function `build_cnn_model` that accepts several hyperparameters:\n",
    "- **learning_rate**: for the optimizer\n",
    "- **optimizer_choice**: e.g., `'adam'` or `'sgd'`\n",
    "- **batch_size**: used during training\n",
    "- **activation**: activation function for the final classification layer (for binary classification, typically `sigmoid` is used)\n",
    "\n",
    "For binary classification, we use a final Dense layer with 1 neuron and a `sigmoid` activation. You can experiment with other activations (though for binary tasks, `sigmoid` is most common)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varni\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">589,952</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m589,952\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">683,329</span> (2.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m683,329\u001b[0m (2.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">683,329</span> (2.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m683,329\u001b[0m (2.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_cnn_model(learning_rate=0.001, optimizer_choice='adam', final_activation='sigmoid', input_shape=(64, 64, 3)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # For binary classification, output one neuron\n",
    "    model.add(Dense(1, activation=final_activation))\n",
    "    \n",
    "    if optimizer_choice.lower() == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice.lower() == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optimizer choice\")\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Build a baseline model\n",
    "baseline_model = build_cnn_model()\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the CNN Model with Hyperparameter Variations\n",
    "\n",
    "Here we train the CNN using various hyperparameters. You can experiment by changing the learning rate, optimizer, batch size, or even the final activation (though for binary classification, `sigmoid` is typical). In this example, we run a few experiments and store the test accuracy for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running experiment: Baseline\n",
      "Epoch 1/100\n",
      "102/102 - 28s - 273ms/step - accuracy: 0.7731 - loss: 0.4525 - val_accuracy: 0.8908 - val_loss: 0.2805\n",
      "Epoch 2/100\n",
      "102/102 - 17s - 167ms/step - accuracy: 0.9002 - loss: 0.2696 - val_accuracy: 0.9264 - val_loss: 0.2170\n",
      "Epoch 3/100\n",
      "102/102 - 19s - 182ms/step - accuracy: 0.9239 - loss: 0.2099 - val_accuracy: 0.9387 - val_loss: 0.1731\n",
      "Epoch 4/100\n",
      "102/102 - 18s - 177ms/step - accuracy: 0.9355 - loss: 0.1834 - val_accuracy: 0.9337 - val_loss: 0.1756\n",
      "Epoch 5/100\n",
      "102/102 - 26s - 251ms/step - accuracy: 0.9429 - loss: 0.1650 - val_accuracy: 0.9362 - val_loss: 0.1579\n",
      "Epoch 6/100\n",
      "102/102 - 17s - 171ms/step - accuracy: 0.9512 - loss: 0.1402 - val_accuracy: 0.9607 - val_loss: 0.1197\n",
      "Epoch 7/100\n",
      "102/102 - 20s - 191ms/step - accuracy: 0.9613 - loss: 0.1158 - val_accuracy: 0.9227 - val_loss: 0.1940\n",
      "Epoch 8/100\n",
      "102/102 - 12s - 118ms/step - accuracy: 0.9598 - loss: 0.1103 - val_accuracy: 0.9632 - val_loss: 0.1187\n",
      "Epoch 9/100\n",
      "102/102 - 13s - 123ms/step - accuracy: 0.9699 - loss: 0.0901 - val_accuracy: 0.9374 - val_loss: 0.1693\n",
      "Epoch 10/100\n",
      "102/102 - 12s - 119ms/step - accuracy: 0.9693 - loss: 0.0769 - val_accuracy: 0.9693 - val_loss: 0.1061\n",
      "Epoch 11/100\n",
      "102/102 - 13s - 126ms/step - accuracy: 0.9727 - loss: 0.0749 - val_accuracy: 0.9644 - val_loss: 0.1248\n",
      "Epoch 12/100\n",
      "102/102 - 12s - 121ms/step - accuracy: 0.9773 - loss: 0.0666 - val_accuracy: 0.9571 - val_loss: 0.1350\n",
      "Epoch 13/100\n",
      "102/102 - 12s - 117ms/step - accuracy: 0.9828 - loss: 0.0460 - val_accuracy: 0.9288 - val_loss: 0.2223\n",
      "Epoch 14/100\n",
      "102/102 - 7s - 65ms/step - accuracy: 0.9813 - loss: 0.0484 - val_accuracy: 0.9779 - val_loss: 0.1024\n",
      "Epoch 15/100\n",
      "102/102 - 6s - 62ms/step - accuracy: 0.9905 - loss: 0.0289 - val_accuracy: 0.9730 - val_loss: 0.1158\n",
      "Epoch 16/100\n",
      "102/102 - 6s - 59ms/step - accuracy: 0.9902 - loss: 0.0276 - val_accuracy: 0.9681 - val_loss: 0.1430\n",
      "Epoch 17/100\n",
      "102/102 - 6s - 60ms/step - accuracy: 0.9920 - loss: 0.0232 - val_accuracy: 0.9546 - val_loss: 0.1893\n",
      "Epoch 18/100\n",
      "102/102 - 6s - 62ms/step - accuracy: 0.9926 - loss: 0.0250 - val_accuracy: 0.9730 - val_loss: 0.1465\n",
      "Epoch 19/100\n",
      "102/102 - 7s - 64ms/step - accuracy: 0.9874 - loss: 0.0328 - val_accuracy: 0.9742 - val_loss: 0.1262\n",
      "Epoch 20/100\n",
      "102/102 - 7s - 65ms/step - accuracy: 0.9957 - loss: 0.0185 - val_accuracy: 0.9755 - val_loss: 0.1314\n",
      "Epoch 21/100\n",
      "102/102 - 7s - 66ms/step - accuracy: 0.9926 - loss: 0.0217 - val_accuracy: 0.9644 - val_loss: 0.1589\n",
      "Epoch 22/100\n",
      "102/102 - 7s - 67ms/step - accuracy: 0.9865 - loss: 0.0391 - val_accuracy: 0.9620 - val_loss: 0.1530\n",
      "Epoch 23/100\n",
      "102/102 - 6s - 61ms/step - accuracy: 0.9923 - loss: 0.0204 - val_accuracy: 0.9718 - val_loss: 0.1465\n",
      "Epoch 24/100\n",
      "102/102 - 5s - 54ms/step - accuracy: 0.9982 - loss: 0.0107 - val_accuracy: 0.9706 - val_loss: 0.1641\n",
      "Epoch 25/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9893 - loss: 0.0292 - val_accuracy: 0.9755 - val_loss: 0.1291\n",
      "Epoch 26/100\n",
      "102/102 - 6s - 58ms/step - accuracy: 0.9969 - loss: 0.0127 - val_accuracy: 0.9755 - val_loss: 0.1437\n",
      "Epoch 27/100\n",
      "102/102 - 9s - 91ms/step - accuracy: 0.9939 - loss: 0.0187 - val_accuracy: 0.9730 - val_loss: 0.1252\n",
      "Epoch 28/100\n",
      "102/102 - 10s - 95ms/step - accuracy: 0.9972 - loss: 0.0084 - val_accuracy: 0.9755 - val_loss: 0.1433\n",
      "Epoch 29/100\n",
      "102/102 - 13s - 131ms/step - accuracy: 0.9905 - loss: 0.0310 - val_accuracy: 0.9693 - val_loss: 0.1428\n",
      "Epoch 30/100\n",
      "102/102 - 9s - 87ms/step - accuracy: 0.9975 - loss: 0.0094 - val_accuracy: 0.9620 - val_loss: 0.1829\n",
      "Epoch 31/100\n",
      "102/102 - 7s - 67ms/step - accuracy: 0.9975 - loss: 0.0105 - val_accuracy: 0.9693 - val_loss: 0.1572\n",
      "Epoch 32/100\n",
      "102/102 - 7s - 71ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 0.9681 - val_loss: 0.1551\n",
      "Epoch 33/100\n",
      "102/102 - 7s - 65ms/step - accuracy: 0.9975 - loss: 0.0072 - val_accuracy: 0.9693 - val_loss: 0.2096\n",
      "Epoch 34/100\n",
      "102/102 - 7s - 66ms/step - accuracy: 0.9954 - loss: 0.0111 - val_accuracy: 0.9742 - val_loss: 0.1718\n",
      "Epoch 35/100\n",
      "102/102 - 6s - 59ms/step - accuracy: 0.9960 - loss: 0.0133 - val_accuracy: 0.9730 - val_loss: 0.1578\n",
      "Epoch 36/100\n",
      "102/102 - 6s - 54ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9681 - val_loss: 0.2088\n",
      "Epoch 37/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9929 - loss: 0.0243 - val_accuracy: 0.9288 - val_loss: 0.2713\n",
      "Epoch 38/100\n",
      "102/102 - 6s - 58ms/step - accuracy: 0.9862 - loss: 0.0427 - val_accuracy: 0.9706 - val_loss: 0.1484\n",
      "Epoch 39/100\n",
      "102/102 - 6s - 59ms/step - accuracy: 0.9979 - loss: 0.0073 - val_accuracy: 0.9632 - val_loss: 0.1800\n",
      "Epoch 40/100\n",
      "102/102 - 6s - 58ms/step - accuracy: 0.9991 - loss: 0.0055 - val_accuracy: 0.9779 - val_loss: 0.1724\n",
      "Epoch 41/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9755 - val_loss: 0.1838\n",
      "Epoch 42/100\n",
      "102/102 - 6s - 59ms/step - accuracy: 0.9988 - loss: 0.0049 - val_accuracy: 0.9742 - val_loss: 0.2070\n",
      "Epoch 43/100\n",
      "102/102 - 6s - 59ms/step - accuracy: 0.9988 - loss: 0.0047 - val_accuracy: 0.9742 - val_loss: 0.1823\n",
      "Epoch 44/100\n",
      "102/102 - 6s - 57ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.9693 - val_loss: 0.1781\n",
      "Epoch 45/100\n",
      "102/102 - 6s - 60ms/step - accuracy: 0.9942 - loss: 0.0171 - val_accuracy: 0.9755 - val_loss: 0.2385\n",
      "Epoch 46/100\n",
      "102/102 - 6s - 60ms/step - accuracy: 0.9975 - loss: 0.0069 - val_accuracy: 0.9767 - val_loss: 0.1951\n",
      "Epoch 47/100\n",
      "102/102 - 6s - 59ms/step - accuracy: 0.9985 - loss: 0.0040 - val_accuracy: 0.9693 - val_loss: 0.2155\n",
      "Epoch 48/100\n",
      "102/102 - 6s - 58ms/step - accuracy: 0.9954 - loss: 0.0187 - val_accuracy: 0.9742 - val_loss: 0.1793\n",
      "Epoch 49/100\n",
      "102/102 - 6s - 60ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.9779 - val_loss: 0.1903\n",
      "Epoch 50/100\n",
      "102/102 - 10s - 101ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9718 - val_loss: 0.2285\n",
      "Epoch 51/100\n",
      "102/102 - 8s - 79ms/step - accuracy: 0.9893 - loss: 0.0352 - val_accuracy: 0.9693 - val_loss: 0.1650\n",
      "Epoch 52/100\n",
      "102/102 - 9s - 83ms/step - accuracy: 0.9954 - loss: 0.0184 - val_accuracy: 0.9742 - val_loss: 0.1767\n",
      "Epoch 53/100\n",
      "102/102 - 9s - 92ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.9779 - val_loss: 0.1760\n",
      "Epoch 54/100\n",
      "102/102 - 11s - 108ms/step - accuracy: 1.0000 - loss: 5.5421e-04 - val_accuracy: 0.9730 - val_loss: 0.1908\n",
      "Epoch 55/100\n",
      "102/102 - 11s - 111ms/step - accuracy: 0.9997 - loss: 9.5849e-04 - val_accuracy: 0.9755 - val_loss: 0.1938\n",
      "Epoch 56/100\n",
      "102/102 - 11s - 110ms/step - accuracy: 1.0000 - loss: 4.8624e-04 - val_accuracy: 0.9718 - val_loss: 0.2025\n",
      "Epoch 57/100\n",
      "102/102 - 12s - 115ms/step - accuracy: 1.0000 - loss: 7.3785e-04 - val_accuracy: 0.9730 - val_loss: 0.2051\n",
      "Epoch 58/100\n",
      "102/102 - 7s - 69ms/step - accuracy: 1.0000 - loss: 4.6544e-04 - val_accuracy: 0.9706 - val_loss: 0.2292\n",
      "Epoch 59/100\n",
      "102/102 - 7s - 64ms/step - accuracy: 0.9850 - loss: 0.0526 - val_accuracy: 0.9607 - val_loss: 0.1942\n",
      "Epoch 60/100\n",
      "102/102 - 6s - 62ms/step - accuracy: 0.9960 - loss: 0.0110 - val_accuracy: 0.9755 - val_loss: 0.1678\n",
      "Epoch 61/100\n",
      "102/102 - 7s - 68ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.9730 - val_loss: 0.1812\n",
      "Epoch 62/100\n",
      "102/102 - 6s - 59ms/step - accuracy: 1.0000 - loss: 6.5259e-04 - val_accuracy: 0.9730 - val_loss: 0.2084\n",
      "Epoch 63/100\n",
      "102/102 - 6s - 61ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9681 - val_loss: 0.1884\n",
      "Epoch 64/100\n",
      "102/102 - 8s - 82ms/step - accuracy: 1.0000 - loss: 6.4632e-04 - val_accuracy: 0.9767 - val_loss: 0.2464\n",
      "Epoch 65/100\n",
      "102/102 - 10s - 99ms/step - accuracy: 0.9969 - loss: 0.0082 - val_accuracy: 0.9644 - val_loss: 0.2381\n",
      "Epoch 66/100\n",
      "102/102 - 8s - 75ms/step - accuracy: 0.9975 - loss: 0.0083 - val_accuracy: 0.9656 - val_loss: 0.2052\n",
      "Epoch 67/100\n",
      "102/102 - 11s - 112ms/step - accuracy: 0.9966 - loss: 0.0128 - val_accuracy: 0.9742 - val_loss: 0.1469\n",
      "Epoch 68/100\n",
      "102/102 - 7s - 66ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.9656 - val_loss: 0.2064\n",
      "Epoch 69/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9997 - loss: 0.0023 - val_accuracy: 0.9730 - val_loss: 0.1773\n",
      "Epoch 70/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 1.0000 - loss: 5.3058e-04 - val_accuracy: 0.9742 - val_loss: 0.1896\n",
      "Epoch 71/100\n",
      "102/102 - 8s - 79ms/step - accuracy: 1.0000 - loss: 2.5361e-04 - val_accuracy: 0.9742 - val_loss: 0.1837\n",
      "Epoch 72/100\n",
      "102/102 - 12s - 119ms/step - accuracy: 1.0000 - loss: 2.4929e-04 - val_accuracy: 0.9730 - val_loss: 0.1955\n",
      "Epoch 73/100\n",
      "102/102 - 7s - 66ms/step - accuracy: 1.0000 - loss: 7.1321e-04 - val_accuracy: 0.9755 - val_loss: 0.1992\n",
      "Epoch 74/100\n",
      "102/102 - 5s - 53ms/step - accuracy: 1.0000 - loss: 3.0379e-04 - val_accuracy: 0.9706 - val_loss: 0.2006\n",
      "Epoch 75/100\n",
      "102/102 - 6s - 61ms/step - accuracy: 0.9997 - loss: 8.4091e-04 - val_accuracy: 0.9706 - val_loss: 0.2335\n",
      "Epoch 76/100\n",
      "102/102 - 6s - 59ms/step - accuracy: 0.9877 - loss: 0.0398 - val_accuracy: 0.9706 - val_loss: 0.2121\n",
      "Epoch 77/100\n",
      "102/102 - 6s - 61ms/step - accuracy: 0.9966 - loss: 0.0098 - val_accuracy: 0.9497 - val_loss: 0.4809\n",
      "Epoch 78/100\n",
      "102/102 - 6s - 59ms/step - accuracy: 0.9886 - loss: 0.0479 - val_accuracy: 0.9767 - val_loss: 0.1709\n",
      "Epoch 79/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.9929 - loss: 0.0238 - val_accuracy: 0.9669 - val_loss: 0.2032\n",
      "Epoch 80/100\n",
      "102/102 - 8s - 74ms/step - accuracy: 0.9997 - loss: 0.0039 - val_accuracy: 0.9730 - val_loss: 0.1878\n",
      "Epoch 81/100\n",
      "102/102 - 11s - 112ms/step - accuracy: 1.0000 - loss: 6.6519e-04 - val_accuracy: 0.9791 - val_loss: 0.1976\n",
      "Epoch 82/100\n",
      "102/102 - 13s - 131ms/step - accuracy: 1.0000 - loss: 2.6305e-04 - val_accuracy: 0.9767 - val_loss: 0.2317\n",
      "Epoch 83/100\n",
      "102/102 - 7s - 66ms/step - accuracy: 0.9991 - loss: 0.0018 - val_accuracy: 0.9816 - val_loss: 0.2340\n",
      "Epoch 84/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 1.0000 - loss: 4.6988e-04 - val_accuracy: 0.9742 - val_loss: 0.2435\n",
      "Epoch 85/100\n",
      "102/102 - 6s - 58ms/step - accuracy: 0.9997 - loss: 0.0027 - val_accuracy: 0.9693 - val_loss: 0.2273\n",
      "Epoch 86/100\n",
      "102/102 - 13s - 126ms/step - accuracy: 0.9979 - loss: 0.0089 - val_accuracy: 0.9669 - val_loss: 0.2375\n",
      "Epoch 87/100\n",
      "102/102 - 9s - 93ms/step - accuracy: 0.9896 - loss: 0.0276 - val_accuracy: 0.9706 - val_loss: 0.2131\n",
      "Epoch 88/100\n",
      "102/102 - 9s - 84ms/step - accuracy: 0.9951 - loss: 0.0140 - val_accuracy: 0.9718 - val_loss: 0.2234\n",
      "Epoch 89/100\n",
      "102/102 - 8s - 82ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 0.9742 - val_loss: 0.2133\n",
      "Epoch 90/100\n",
      "102/102 - 10s - 100ms/step - accuracy: 0.9969 - loss: 0.0083 - val_accuracy: 0.9693 - val_loss: 0.2215\n",
      "Epoch 91/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9755 - val_loss: 0.2278\n",
      "Epoch 92/100\n",
      "102/102 - 6s - 57ms/step - accuracy: 1.0000 - loss: 4.7805e-04 - val_accuracy: 0.9742 - val_loss: 0.2375\n",
      "Epoch 93/100\n",
      "102/102 - 5s - 54ms/step - accuracy: 1.0000 - loss: 2.5036e-04 - val_accuracy: 0.9742 - val_loss: 0.2424\n",
      "Epoch 94/100\n",
      "102/102 - 6s - 57ms/step - accuracy: 1.0000 - loss: 2.9791e-04 - val_accuracy: 0.9755 - val_loss: 0.2410\n",
      "Epoch 95/100\n",
      "102/102 - 5s - 54ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9791 - val_loss: 0.2502\n",
      "Epoch 96/100\n",
      "102/102 - 5s - 53ms/step - accuracy: 1.0000 - loss: 1.9210e-04 - val_accuracy: 0.9791 - val_loss: 0.2412\n",
      "Epoch 97/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 1.0000 - loss: 3.2637e-04 - val_accuracy: 0.9755 - val_loss: 0.2381\n",
      "Epoch 98/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 1.0000 - loss: 1.9794e-04 - val_accuracy: 0.9718 - val_loss: 0.2575\n",
      "Epoch 99/100\n",
      "102/102 - 6s - 57ms/step - accuracy: 1.0000 - loss: 1.6132e-04 - val_accuracy: 0.9718 - val_loss: 0.2507\n",
      "Epoch 100/100\n",
      "102/102 - 6s - 62ms/step - accuracy: 1.0000 - loss: 9.7818e-05 - val_accuracy: 0.9742 - val_loss: 0.2638\n",
      "Test Accuracy for Baseline: 0.9742\n",
      "\n",
      "Running experiment: Low LR\n",
      "Epoch 1/100\n",
      "102/102 - 10s - 94ms/step - accuracy: 0.7599 - loss: 0.5282 - val_accuracy: 0.8748 - val_loss: 0.3583\n",
      "Epoch 2/100\n",
      "102/102 - 7s - 67ms/step - accuracy: 0.8790 - loss: 0.3338 - val_accuracy: 0.8933 - val_loss: 0.3145\n",
      "Epoch 3/100\n",
      "102/102 - 7s - 65ms/step - accuracy: 0.9014 - loss: 0.2806 - val_accuracy: 0.9018 - val_loss: 0.2773\n",
      "Epoch 4/100\n",
      "102/102 - 6s - 63ms/step - accuracy: 0.9042 - loss: 0.2613 - val_accuracy: 0.9018 - val_loss: 0.2540\n",
      "Epoch 5/100\n",
      "102/102 - 6s - 60ms/step - accuracy: 0.9076 - loss: 0.2464 - val_accuracy: 0.9080 - val_loss: 0.2479\n",
      "Epoch 6/100\n",
      "102/102 - 6s - 61ms/step - accuracy: 0.9153 - loss: 0.2259 - val_accuracy: 0.9080 - val_loss: 0.2245\n",
      "Epoch 7/100\n",
      "102/102 - 6s - 62ms/step - accuracy: 0.9235 - loss: 0.2102 - val_accuracy: 0.9043 - val_loss: 0.2217\n",
      "Epoch 8/100\n",
      "102/102 - 6s - 57ms/step - accuracy: 0.9257 - loss: 0.1967 - val_accuracy: 0.8945 - val_loss: 0.2561\n",
      "Epoch 9/100\n",
      "102/102 - 6s - 57ms/step - accuracy: 0.9352 - loss: 0.1783 - val_accuracy: 0.9117 - val_loss: 0.2108\n",
      "Epoch 10/100\n",
      "102/102 - 6s - 60ms/step - accuracy: 0.9411 - loss: 0.1673 - val_accuracy: 0.9092 - val_loss: 0.2243\n",
      "Epoch 11/100\n",
      "102/102 - 6s - 58ms/step - accuracy: 0.9453 - loss: 0.1517 - val_accuracy: 0.9387 - val_loss: 0.1644\n",
      "Epoch 12/100\n",
      "102/102 - 6s - 63ms/step - accuracy: 0.9463 - loss: 0.1483 - val_accuracy: 0.9423 - val_loss: 0.1558\n",
      "Epoch 13/100\n",
      "102/102 - 7s - 67ms/step - accuracy: 0.9530 - loss: 0.1360 - val_accuracy: 0.9436 - val_loss: 0.1536\n",
      "Epoch 14/100\n",
      "102/102 - 6s - 59ms/step - accuracy: 0.9592 - loss: 0.1213 - val_accuracy: 0.9362 - val_loss: 0.1528\n",
      "Epoch 15/100\n",
      "102/102 - 6s - 58ms/step - accuracy: 0.9601 - loss: 0.1165 - val_accuracy: 0.9337 - val_loss: 0.1573\n",
      "Epoch 16/100\n",
      "102/102 - 6s - 58ms/step - accuracy: 0.9635 - loss: 0.1090 - val_accuracy: 0.9521 - val_loss: 0.1312\n",
      "Epoch 17/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9622 - loss: 0.1015 - val_accuracy: 0.9632 - val_loss: 0.1212\n",
      "Epoch 18/100\n",
      "102/102 - 7s - 67ms/step - accuracy: 0.9684 - loss: 0.0905 - val_accuracy: 0.9632 - val_loss: 0.1150\n",
      "Epoch 19/100\n",
      "102/102 - 6s - 57ms/step - accuracy: 0.9714 - loss: 0.0918 - val_accuracy: 0.9546 - val_loss: 0.1214\n",
      "Epoch 20/100\n",
      "102/102 - 6s - 54ms/step - accuracy: 0.9745 - loss: 0.0804 - val_accuracy: 0.9644 - val_loss: 0.1080\n",
      "Epoch 21/100\n",
      "102/102 - 5s - 53ms/step - accuracy: 0.9736 - loss: 0.0738 - val_accuracy: 0.9669 - val_loss: 0.1124\n",
      "Epoch 22/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9770 - loss: 0.0713 - val_accuracy: 0.9669 - val_loss: 0.1067\n",
      "Epoch 23/100\n",
      "102/102 - 6s - 59ms/step - accuracy: 0.9748 - loss: 0.0706 - val_accuracy: 0.9620 - val_loss: 0.1102\n",
      "Epoch 24/100\n",
      "102/102 - 6s - 61ms/step - accuracy: 0.9776 - loss: 0.0666 - val_accuracy: 0.9693 - val_loss: 0.1020\n",
      "Epoch 25/100\n",
      "102/102 - 6s - 63ms/step - accuracy: 0.9840 - loss: 0.0538 - val_accuracy: 0.9681 - val_loss: 0.0977\n",
      "Epoch 26/100\n",
      "102/102 - 5s - 53ms/step - accuracy: 0.9816 - loss: 0.0552 - val_accuracy: 0.9558 - val_loss: 0.1176\n",
      "Epoch 27/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9843 - loss: 0.0512 - val_accuracy: 0.9669 - val_loss: 0.1012\n",
      "Epoch 28/100\n",
      "102/102 - 5s - 54ms/step - accuracy: 0.9831 - loss: 0.0487 - val_accuracy: 0.9656 - val_loss: 0.0972\n",
      "Epoch 29/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.9834 - loss: 0.0479 - val_accuracy: 0.9607 - val_loss: 0.1080\n",
      "Epoch 30/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9856 - loss: 0.0440 - val_accuracy: 0.9693 - val_loss: 0.0940\n",
      "Epoch 31/100\n",
      "102/102 - 6s - 54ms/step - accuracy: 0.9868 - loss: 0.0410 - val_accuracy: 0.9632 - val_loss: 0.1008\n",
      "Epoch 32/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9868 - loss: 0.0400 - val_accuracy: 0.9620 - val_loss: 0.1227\n",
      "Epoch 33/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.9889 - loss: 0.0347 - val_accuracy: 0.9693 - val_loss: 0.0962\n",
      "Epoch 34/100\n",
      "102/102 - 6s - 58ms/step - accuracy: 0.9914 - loss: 0.0321 - val_accuracy: 0.9755 - val_loss: 0.1026\n",
      "Epoch 35/100\n",
      "102/102 - 6s - 57ms/step - accuracy: 0.9893 - loss: 0.0291 - val_accuracy: 0.9706 - val_loss: 0.1062\n",
      "Epoch 36/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9914 - loss: 0.0276 - val_accuracy: 0.9706 - val_loss: 0.0985\n",
      "Epoch 37/100\n",
      "102/102 - 6s - 54ms/step - accuracy: 0.9923 - loss: 0.0274 - val_accuracy: 0.9742 - val_loss: 0.0992\n",
      "Epoch 38/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9929 - loss: 0.0238 - val_accuracy: 0.9595 - val_loss: 0.1147\n",
      "Epoch 39/100\n",
      "102/102 - 6s - 63ms/step - accuracy: 0.9936 - loss: 0.0229 - val_accuracy: 0.9767 - val_loss: 0.1021\n",
      "Epoch 40/100\n",
      "102/102 - 6s - 60ms/step - accuracy: 0.9954 - loss: 0.0205 - val_accuracy: 0.9767 - val_loss: 0.1055\n",
      "Epoch 41/100\n",
      "102/102 - 6s - 57ms/step - accuracy: 0.9969 - loss: 0.0173 - val_accuracy: 0.9742 - val_loss: 0.1035\n",
      "Epoch 42/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.9972 - loss: 0.0156 - val_accuracy: 0.9767 - val_loss: 0.1108\n",
      "Epoch 43/100\n",
      "102/102 - 6s - 58ms/step - accuracy: 0.9963 - loss: 0.0149 - val_accuracy: 0.9681 - val_loss: 0.1122\n",
      "Epoch 44/100\n",
      "102/102 - 6s - 59ms/step - accuracy: 0.9963 - loss: 0.0163 - val_accuracy: 0.9742 - val_loss: 0.1071\n",
      "Epoch 45/100\n",
      "102/102 - 6s - 59ms/step - accuracy: 0.9988 - loss: 0.0120 - val_accuracy: 0.9681 - val_loss: 0.1089\n",
      "Epoch 46/100\n",
      "102/102 - 6s - 57ms/step - accuracy: 0.9963 - loss: 0.0134 - val_accuracy: 0.9521 - val_loss: 0.1627\n",
      "Epoch 47/100\n",
      "102/102 - 6s - 57ms/step - accuracy: 0.9963 - loss: 0.0173 - val_accuracy: 0.9767 - val_loss: 0.1169\n",
      "Epoch 48/100\n",
      "102/102 - 6s - 58ms/step - accuracy: 0.9985 - loss: 0.0101 - val_accuracy: 0.9742 - val_loss: 0.1153\n",
      "Epoch 49/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.9988 - loss: 0.0094 - val_accuracy: 0.9742 - val_loss: 0.1156\n",
      "Epoch 50/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.9966 - loss: 0.0116 - val_accuracy: 0.9706 - val_loss: 0.1151\n",
      "Epoch 51/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.9994 - loss: 0.0080 - val_accuracy: 0.9706 - val_loss: 0.1282\n",
      "Epoch 52/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.9985 - loss: 0.0092 - val_accuracy: 0.9767 - val_loss: 0.1177\n",
      "Epoch 53/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.9994 - loss: 0.0077 - val_accuracy: 0.9730 - val_loss: 0.1305\n",
      "Epoch 54/100\n",
      "102/102 - 6s - 58ms/step - accuracy: 0.9982 - loss: 0.0079 - val_accuracy: 0.9681 - val_loss: 0.1251\n",
      "Epoch 55/100\n",
      "102/102 - 6s - 59ms/step - accuracy: 0.9994 - loss: 0.0061 - val_accuracy: 0.9706 - val_loss: 0.1313\n",
      "Epoch 56/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.9994 - loss: 0.0058 - val_accuracy: 0.9742 - val_loss: 0.1250\n",
      "Epoch 57/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9994 - loss: 0.0056 - val_accuracy: 0.9730 - val_loss: 0.1312\n",
      "Epoch 58/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.9994 - loss: 0.0054 - val_accuracy: 0.9730 - val_loss: 0.1273\n",
      "Epoch 59/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9991 - loss: 0.0050 - val_accuracy: 0.9669 - val_loss: 0.1419\n",
      "Epoch 60/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.9994 - loss: 0.0033 - val_accuracy: 0.9669 - val_loss: 0.1399\n",
      "Epoch 61/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9945 - loss: 0.0177 - val_accuracy: 0.9718 - val_loss: 0.1326\n",
      "Epoch 62/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9991 - loss: 0.0073 - val_accuracy: 0.9718 - val_loss: 0.1342\n",
      "Epoch 63/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9997 - loss: 0.0037 - val_accuracy: 0.9755 - val_loss: 0.1372\n",
      "Epoch 64/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9706 - val_loss: 0.1506\n",
      "Epoch 65/100\n",
      "102/102 - 6s - 57ms/step - accuracy: 0.9997 - loss: 0.0032 - val_accuracy: 0.9742 - val_loss: 0.1361\n",
      "Epoch 66/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9997 - loss: 0.0042 - val_accuracy: 0.9742 - val_loss: 0.1424\n",
      "Epoch 67/100\n",
      "102/102 - 6s - 58ms/step - accuracy: 0.9997 - loss: 0.0024 - val_accuracy: 0.9718 - val_loss: 0.1423\n",
      "Epoch 68/100\n",
      "102/102 - 10s - 100ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9742 - val_loss: 0.1452\n",
      "Epoch 69/100\n",
      "102/102 - 6s - 57ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9706 - val_loss: 0.1521\n",
      "Epoch 70/100\n",
      "102/102 - 6s - 54ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.9693 - val_loss: 0.1430\n",
      "Epoch 71/100\n",
      "102/102 - 6s - 54ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9767 - val_loss: 0.1521\n",
      "Epoch 72/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9742 - val_loss: 0.1588\n",
      "Epoch 73/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.9982 - loss: 0.0054 - val_accuracy: 0.9644 - val_loss: 0.1598\n",
      "Epoch 74/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.9982 - loss: 0.0075 - val_accuracy: 0.9656 - val_loss: 0.1516\n",
      "Epoch 75/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.9945 - loss: 0.0155 - val_accuracy: 0.9681 - val_loss: 0.1409\n",
      "Epoch 76/100\n",
      "102/102 - 5s - 53ms/step - accuracy: 0.9991 - loss: 0.0056 - val_accuracy: 0.9730 - val_loss: 0.1564\n",
      "Epoch 77/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.9755 - val_loss: 0.1689\n",
      "Epoch 78/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.9706 - val_loss: 0.1596\n",
      "Epoch 79/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9718 - val_loss: 0.1631\n",
      "Epoch 80/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9718 - val_loss: 0.1681\n",
      "Epoch 81/100\n",
      "102/102 - 6s - 54ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9718 - val_loss: 0.1628\n",
      "Epoch 82/100\n",
      "102/102 - 5s - 54ms/step - accuracy: 1.0000 - loss: 7.7651e-04 - val_accuracy: 0.9693 - val_loss: 0.1653\n",
      "Epoch 83/100\n",
      "102/102 - 5s - 53ms/step - accuracy: 1.0000 - loss: 7.6809e-04 - val_accuracy: 0.9730 - val_loss: 0.1683\n",
      "Epoch 84/100\n",
      "102/102 - 5s - 53ms/step - accuracy: 1.0000 - loss: 8.0300e-04 - val_accuracy: 0.9706 - val_loss: 0.1704\n",
      "Epoch 85/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 1.0000 - loss: 5.0455e-04 - val_accuracy: 0.9742 - val_loss: 0.1716\n",
      "Epoch 86/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 1.0000 - loss: 6.5879e-04 - val_accuracy: 0.9742 - val_loss: 0.1695\n",
      "Epoch 87/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 1.0000 - loss: 8.6175e-04 - val_accuracy: 0.9730 - val_loss: 0.1731\n",
      "Epoch 88/100\n",
      "102/102 - 5s - 53ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9706 - val_loss: 0.1701\n",
      "Epoch 89/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 1.0000 - loss: 5.9040e-04 - val_accuracy: 0.9693 - val_loss: 0.1755\n",
      "Epoch 90/100\n",
      "102/102 - 5s - 53ms/step - accuracy: 1.0000 - loss: 4.6836e-04 - val_accuracy: 0.9693 - val_loss: 0.1838\n",
      "Epoch 91/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 1.0000 - loss: 5.4307e-04 - val_accuracy: 0.9669 - val_loss: 0.1982\n",
      "Epoch 92/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 1.0000 - loss: 7.3893e-04 - val_accuracy: 0.9706 - val_loss: 0.1831\n",
      "Epoch 93/100\n",
      "102/102 - 5s - 53ms/step - accuracy: 1.0000 - loss: 6.9400e-04 - val_accuracy: 0.9755 - val_loss: 0.1746\n",
      "Epoch 94/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 1.0000 - loss: 4.6793e-04 - val_accuracy: 0.9718 - val_loss: 0.1799\n",
      "Epoch 95/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 1.0000 - loss: 4.1149e-04 - val_accuracy: 0.9706 - val_loss: 0.1860\n",
      "Epoch 96/100\n",
      "102/102 - 5s - 53ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9730 - val_loss: 0.1801\n",
      "Epoch 97/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9718 - val_loss: 0.2073\n",
      "Epoch 98/100\n",
      "102/102 - 9s - 92ms/step - accuracy: 0.9917 - loss: 0.0277 - val_accuracy: 0.9693 - val_loss: 0.1487\n",
      "Epoch 99/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 0.9693 - val_loss: 0.1513\n",
      "Epoch 100/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.9985 - loss: 0.0044 - val_accuracy: 0.9620 - val_loss: 0.1918\n",
      "Test Accuracy for Low LR: 0.9620\n",
      "\n",
      "Running experiment: High LR\n",
      "Epoch 1/100\n",
      "102/102 - 7s - 68ms/step - accuracy: 0.5183 - loss: 0.9680 - val_accuracy: 0.7583 - val_loss: 0.5660\n",
      "Epoch 2/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8514 - loss: 0.4012 - val_accuracy: 0.8221 - val_loss: 0.4461\n",
      "Epoch 3/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 0.8216 - loss: 0.4353 - val_accuracy: 0.8233 - val_loss: 0.4529\n",
      "Epoch 4/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8582 - loss: 0.3669 - val_accuracy: 0.8810 - val_loss: 0.3003\n",
      "Epoch 5/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8821 - loss: 0.3162 - val_accuracy: 0.8896 - val_loss: 0.3027\n",
      "Epoch 6/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.8800 - loss: 0.3174 - val_accuracy: 0.8822 - val_loss: 0.2941\n",
      "Epoch 7/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 0.8913 - loss: 0.2922 - val_accuracy: 0.9031 - val_loss: 0.2866\n",
      "Epoch 8/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8953 - loss: 0.2797 - val_accuracy: 0.8982 - val_loss: 0.2817\n",
      "Epoch 9/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8925 - loss: 0.2911 - val_accuracy: 0.9092 - val_loss: 0.2688\n",
      "Epoch 10/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.9045 - loss: 0.2536 - val_accuracy: 0.9080 - val_loss: 0.2471\n",
      "Epoch 11/100\n",
      "102/102 - 6s - 57ms/step - accuracy: 0.8962 - loss: 0.2910 - val_accuracy: 0.8675 - val_loss: 0.3284\n",
      "Epoch 12/100\n",
      "102/102 - 6s - 58ms/step - accuracy: 0.9094 - loss: 0.2507 - val_accuracy: 0.8982 - val_loss: 0.2693\n",
      "Epoch 13/100\n",
      "102/102 - 6s - 58ms/step - accuracy: 0.9122 - loss: 0.2338 - val_accuracy: 0.9276 - val_loss: 0.2363\n",
      "Epoch 14/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.9177 - loss: 0.2221 - val_accuracy: 0.9104 - val_loss: 0.2663\n",
      "Epoch 15/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.9242 - loss: 0.2049 - val_accuracy: 0.9252 - val_loss: 0.2293\n",
      "Epoch 16/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.9180 - loss: 0.2203 - val_accuracy: 0.9325 - val_loss: 0.2158\n",
      "Epoch 17/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9239 - loss: 0.2116 - val_accuracy: 0.9166 - val_loss: 0.2317\n",
      "Epoch 18/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9306 - loss: 0.1962 - val_accuracy: 0.9301 - val_loss: 0.2306\n",
      "Epoch 19/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.9325 - loss: 0.1953 - val_accuracy: 0.9399 - val_loss: 0.2152\n",
      "Epoch 20/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9306 - loss: 0.1942 - val_accuracy: 0.9399 - val_loss: 0.2203\n",
      "Epoch 21/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9352 - loss: 0.1792 - val_accuracy: 0.9264 - val_loss: 0.2434\n",
      "Epoch 22/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9361 - loss: 0.1649 - val_accuracy: 0.9313 - val_loss: 0.2502\n",
      "Epoch 23/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9417 - loss: 0.1560 - val_accuracy: 0.9460 - val_loss: 0.2269\n",
      "Epoch 24/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.9389 - loss: 0.1699 - val_accuracy: 0.9264 - val_loss: 0.2529\n",
      "Epoch 25/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9346 - loss: 0.1750 - val_accuracy: 0.9387 - val_loss: 0.2342\n",
      "Epoch 26/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.9300 - loss: 0.1992 - val_accuracy: 0.9264 - val_loss: 0.2008\n",
      "Epoch 27/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9352 - loss: 0.1969 - val_accuracy: 0.9264 - val_loss: 0.2188\n",
      "Epoch 28/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.9355 - loss: 0.1653 - val_accuracy: 0.9313 - val_loss: 0.2349\n",
      "Epoch 29/100\n",
      "102/102 - 6s - 54ms/step - accuracy: 0.9429 - loss: 0.1618 - val_accuracy: 0.9104 - val_loss: 0.2853\n",
      "Epoch 30/100\n",
      "102/102 - 9s - 85ms/step - accuracy: 0.9374 - loss: 0.1574 - val_accuracy: 0.9350 - val_loss: 0.2095\n",
      "Epoch 31/100\n",
      "102/102 - 9s - 84ms/step - accuracy: 0.9460 - loss: 0.1507 - val_accuracy: 0.9374 - val_loss: 0.2345\n",
      "Epoch 32/100\n",
      "102/102 - 9s - 86ms/step - accuracy: 0.9346 - loss: 0.1720 - val_accuracy: 0.9067 - val_loss: 0.2917\n",
      "Epoch 33/100\n",
      "102/102 - 9s - 85ms/step - accuracy: 0.9398 - loss: 0.1729 - val_accuracy: 0.9350 - val_loss: 0.2558\n",
      "Epoch 34/100\n",
      "102/102 - 9s - 90ms/step - accuracy: 0.9392 - loss: 0.1633 - val_accuracy: 0.9252 - val_loss: 0.2968\n",
      "Epoch 35/100\n",
      "102/102 - 10s - 95ms/step - accuracy: 0.9374 - loss: 0.1768 - val_accuracy: 0.9239 - val_loss: 0.2334\n",
      "Epoch 36/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.9383 - loss: 0.1693 - val_accuracy: 0.9374 - val_loss: 0.2308\n",
      "Epoch 37/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.9481 - loss: 0.1350 - val_accuracy: 0.9153 - val_loss: 0.3310\n",
      "Epoch 38/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9503 - loss: 0.1406 - val_accuracy: 0.9264 - val_loss: 0.3558\n",
      "Epoch 39/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.9361 - loss: 0.1692 - val_accuracy: 0.9117 - val_loss: 0.3137\n",
      "Epoch 40/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.9423 - loss: 0.1597 - val_accuracy: 0.9313 - val_loss: 0.3140\n",
      "Epoch 41/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.9481 - loss: 0.1395 - val_accuracy: 0.9325 - val_loss: 0.2519\n",
      "Epoch 42/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.9500 - loss: 0.1376 - val_accuracy: 0.9276 - val_loss: 0.2700\n",
      "Epoch 43/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9414 - loss: 0.1736 - val_accuracy: 0.9092 - val_loss: 0.2802\n",
      "Epoch 44/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.9380 - loss: 0.1496 - val_accuracy: 0.9411 - val_loss: 0.2543\n",
      "Epoch 45/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.9515 - loss: 0.1381 - val_accuracy: 0.9399 - val_loss: 0.2787\n",
      "Epoch 46/100\n",
      "102/102 - 5s - 46ms/step - accuracy: 0.9460 - loss: 0.1432 - val_accuracy: 0.9325 - val_loss: 0.3131\n",
      "Epoch 47/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9530 - loss: 0.1186 - val_accuracy: 0.9337 - val_loss: 0.2821\n",
      "Epoch 48/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.9506 - loss: 0.1343 - val_accuracy: 0.9252 - val_loss: 0.3189\n",
      "Epoch 49/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.9420 - loss: 0.1521 - val_accuracy: 0.9313 - val_loss: 0.2857\n",
      "Epoch 50/100\n",
      "102/102 - 5s - 47ms/step - accuracy: 0.9515 - loss: 0.1394 - val_accuracy: 0.9448 - val_loss: 0.3621\n",
      "Epoch 51/100\n",
      "102/102 - 5s - 47ms/step - accuracy: 0.9539 - loss: 0.1294 - val_accuracy: 0.9141 - val_loss: 0.3869\n",
      "Epoch 52/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9475 - loss: 0.1481 - val_accuracy: 0.9104 - val_loss: 0.3866\n",
      "Epoch 53/100\n",
      "102/102 - 5s - 45ms/step - accuracy: 0.9509 - loss: 0.1402 - val_accuracy: 0.9227 - val_loss: 0.2544\n",
      "Epoch 54/100\n",
      "102/102 - 5s - 46ms/step - accuracy: 0.9386 - loss: 0.1613 - val_accuracy: 0.9399 - val_loss: 0.2860\n",
      "Epoch 55/100\n",
      "102/102 - 5s - 46ms/step - accuracy: 0.9438 - loss: 0.1458 - val_accuracy: 0.9288 - val_loss: 0.3096\n",
      "Epoch 56/100\n",
      "102/102 - 5s - 46ms/step - accuracy: 0.9496 - loss: 0.1370 - val_accuracy: 0.9288 - val_loss: 0.4121\n",
      "Epoch 57/100\n",
      "102/102 - 5s - 45ms/step - accuracy: 0.9423 - loss: 0.1565 - val_accuracy: 0.9129 - val_loss: 0.3927\n",
      "Epoch 58/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9512 - loss: 0.1416 - val_accuracy: 0.9374 - val_loss: 0.3514\n",
      "Epoch 59/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.9530 - loss: 0.1240 - val_accuracy: 0.9043 - val_loss: 0.4357\n",
      "Epoch 60/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.9564 - loss: 0.1215 - val_accuracy: 0.9374 - val_loss: 0.3461\n",
      "Epoch 61/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.9401 - loss: 0.1704 - val_accuracy: 0.9313 - val_loss: 0.3093\n",
      "Epoch 62/100\n",
      "102/102 - 5s - 44ms/step - accuracy: 0.9573 - loss: 0.1233 - val_accuracy: 0.9399 - val_loss: 0.3102\n",
      "Epoch 63/100\n",
      "102/102 - 5s - 45ms/step - accuracy: 0.9613 - loss: 0.1144 - val_accuracy: 0.9362 - val_loss: 0.3261\n",
      "Epoch 64/100\n",
      "102/102 - 5s - 45ms/step - accuracy: 0.9561 - loss: 0.1356 - val_accuracy: 0.9288 - val_loss: 0.4706\n",
      "Epoch 65/100\n",
      "102/102 - 5s - 46ms/step - accuracy: 0.9530 - loss: 0.1302 - val_accuracy: 0.9374 - val_loss: 0.3422\n",
      "Epoch 66/100\n",
      "102/102 - 5s - 45ms/step - accuracy: 0.9543 - loss: 0.1113 - val_accuracy: 0.9374 - val_loss: 0.4484\n",
      "Epoch 67/100\n",
      "102/102 - 5s - 46ms/step - accuracy: 0.9607 - loss: 0.1101 - val_accuracy: 0.9411 - val_loss: 0.4196\n",
      "Epoch 68/100\n",
      "102/102 - 5s - 45ms/step - accuracy: 0.9576 - loss: 0.1258 - val_accuracy: 0.9374 - val_loss: 0.3792\n",
      "Epoch 69/100\n",
      "102/102 - 5s - 46ms/step - accuracy: 0.9570 - loss: 0.1172 - val_accuracy: 0.9387 - val_loss: 0.3593\n",
      "Epoch 70/100\n",
      "102/102 - 5s - 45ms/step - accuracy: 0.9616 - loss: 0.1178 - val_accuracy: 0.9423 - val_loss: 0.3770\n",
      "Epoch 71/100\n",
      "102/102 - 5s - 46ms/step - accuracy: 0.9555 - loss: 0.1136 - val_accuracy: 0.9411 - val_loss: 0.4468\n",
      "Epoch 72/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9586 - loss: 0.1195 - val_accuracy: 0.9387 - val_loss: 0.3837\n",
      "Epoch 73/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 0.9613 - loss: 0.1161 - val_accuracy: 0.9202 - val_loss: 0.3826\n",
      "Epoch 74/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.9558 - loss: 0.1249 - val_accuracy: 0.9399 - val_loss: 0.2956\n",
      "Epoch 75/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.9484 - loss: 0.1371 - val_accuracy: 0.9239 - val_loss: 0.5431\n",
      "Epoch 76/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9500 - loss: 0.1373 - val_accuracy: 0.9202 - val_loss: 0.4281\n",
      "Epoch 77/100\n",
      "102/102 - 6s - 57ms/step - accuracy: 0.9527 - loss: 0.1351 - val_accuracy: 0.9190 - val_loss: 0.3792\n",
      "Epoch 78/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 0.9622 - loss: 0.1078 - val_accuracy: 0.9374 - val_loss: 0.4709\n",
      "Epoch 79/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.9586 - loss: 0.1164 - val_accuracy: 0.9202 - val_loss: 0.6024\n",
      "Epoch 80/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.9543 - loss: 0.1449 - val_accuracy: 0.9227 - val_loss: 0.4296\n",
      "Epoch 81/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.9601 - loss: 0.1115 - val_accuracy: 0.9411 - val_loss: 0.4095\n",
      "Epoch 82/100\n",
      "102/102 - 5s - 46ms/step - accuracy: 0.9595 - loss: 0.1141 - val_accuracy: 0.9006 - val_loss: 0.4550\n",
      "Epoch 83/100\n",
      "102/102 - 5s - 47ms/step - accuracy: 0.9447 - loss: 0.1470 - val_accuracy: 0.9325 - val_loss: 0.4253\n",
      "Epoch 84/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 0.9582 - loss: 0.1197 - val_accuracy: 0.9350 - val_loss: 0.5172\n",
      "Epoch 85/100\n",
      "102/102 - 6s - 62ms/step - accuracy: 0.9619 - loss: 0.1057 - val_accuracy: 0.9362 - val_loss: 0.5591\n",
      "Epoch 86/100\n",
      "102/102 - 6s - 57ms/step - accuracy: 0.9659 - loss: 0.0926 - val_accuracy: 0.9423 - val_loss: 0.4593\n",
      "Epoch 87/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.9616 - loss: 0.1024 - val_accuracy: 0.9288 - val_loss: 0.6537\n",
      "Epoch 88/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.9573 - loss: 0.1128 - val_accuracy: 0.9239 - val_loss: 0.5488\n",
      "Epoch 89/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9539 - loss: 0.1298 - val_accuracy: 0.9399 - val_loss: 0.5686\n",
      "Epoch 90/100\n",
      "102/102 - 6s - 55ms/step - accuracy: 0.9632 - loss: 0.1074 - val_accuracy: 0.9411 - val_loss: 0.6488\n",
      "Epoch 91/100\n",
      "102/102 - 7s - 73ms/step - accuracy: 0.9647 - loss: 0.1016 - val_accuracy: 0.9411 - val_loss: 0.7385\n",
      "Epoch 92/100\n",
      "102/102 - 8s - 78ms/step - accuracy: 0.9632 - loss: 0.1017 - val_accuracy: 0.8933 - val_loss: 0.6300\n",
      "Epoch 93/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.9533 - loss: 0.1576 - val_accuracy: 0.9411 - val_loss: 0.3589\n",
      "Epoch 94/100\n",
      "102/102 - 7s - 68ms/step - accuracy: 0.9595 - loss: 0.1258 - val_accuracy: 0.9436 - val_loss: 0.4404\n",
      "Epoch 95/100\n",
      "102/102 - 9s - 84ms/step - accuracy: 0.9650 - loss: 0.1073 - val_accuracy: 0.9313 - val_loss: 0.4791\n",
      "Epoch 96/100\n",
      "102/102 - 7s - 68ms/step - accuracy: 0.9539 - loss: 0.1324 - val_accuracy: 0.9264 - val_loss: 0.6812\n",
      "Epoch 97/100\n",
      "102/102 - 7s - 70ms/step - accuracy: 0.9622 - loss: 0.1085 - val_accuracy: 0.9337 - val_loss: 0.4291\n",
      "Epoch 98/100\n",
      "102/102 - 7s - 71ms/step - accuracy: 0.9644 - loss: 0.1006 - val_accuracy: 0.9215 - val_loss: 0.5753\n",
      "Epoch 99/100\n",
      "102/102 - 7s - 67ms/step - accuracy: 0.9678 - loss: 0.0980 - val_accuracy: 0.9387 - val_loss: 0.5659\n",
      "Epoch 100/100\n",
      "102/102 - 7s - 70ms/step - accuracy: 0.9622 - loss: 0.0989 - val_accuracy: 0.9301 - val_loss: 0.4610\n",
      "Test Accuracy for High LR: 0.9301\n",
      "\n",
      "Running experiment: SGD Optimizer\n",
      "Epoch 1/100\n",
      "102/102 - 9s - 88ms/step - accuracy: 0.5269 - loss: 0.6919 - val_accuracy: 0.6319 - val_loss: 0.6849\n",
      "Epoch 2/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.5523 - loss: 0.6855 - val_accuracy: 0.6822 - val_loss: 0.6809\n",
      "Epoch 3/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.5732 - loss: 0.6833 - val_accuracy: 0.6454 - val_loss: 0.6764\n",
      "Epoch 4/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.5966 - loss: 0.6775 - val_accuracy: 0.7301 - val_loss: 0.6729\n",
      "Epoch 5/100\n",
      "102/102 - 5s - 47ms/step - accuracy: 0.6156 - loss: 0.6736 - val_accuracy: 0.7534 - val_loss: 0.6691\n",
      "Epoch 6/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.6316 - loss: 0.6704 - val_accuracy: 0.7325 - val_loss: 0.6626\n",
      "Epoch 7/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.6638 - loss: 0.6619 - val_accuracy: 0.7804 - val_loss: 0.6583\n",
      "Epoch 8/100\n",
      "102/102 - 5s - 47ms/step - accuracy: 0.6804 - loss: 0.6577 - val_accuracy: 0.7632 - val_loss: 0.6510\n",
      "Epoch 9/100\n",
      "102/102 - 5s - 47ms/step - accuracy: 0.6847 - loss: 0.6503 - val_accuracy: 0.7877 - val_loss: 0.6447\n",
      "Epoch 10/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.6973 - loss: 0.6439 - val_accuracy: 0.7975 - val_loss: 0.6369\n",
      "Epoch 11/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.7221 - loss: 0.6322 - val_accuracy: 0.7828 - val_loss: 0.6287\n",
      "Epoch 12/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.7525 - loss: 0.6197 - val_accuracy: 0.8123 - val_loss: 0.6149\n",
      "Epoch 13/100\n",
      "102/102 - 5s - 46ms/step - accuracy: 0.7599 - loss: 0.6108 - val_accuracy: 0.8123 - val_loss: 0.5980\n",
      "Epoch 14/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.7746 - loss: 0.5926 - val_accuracy: 0.8135 - val_loss: 0.5867\n",
      "Epoch 15/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 0.7961 - loss: 0.5742 - val_accuracy: 0.8221 - val_loss: 0.5607\n",
      "Epoch 16/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.7986 - loss: 0.5544 - val_accuracy: 0.8344 - val_loss: 0.5424\n",
      "Epoch 17/100\n",
      "102/102 - 5s - 45ms/step - accuracy: 0.7983 - loss: 0.5354 - val_accuracy: 0.8282 - val_loss: 0.5162\n",
      "Epoch 18/100\n",
      "102/102 - 5s - 46ms/step - accuracy: 0.8161 - loss: 0.5109 - val_accuracy: 0.8356 - val_loss: 0.5028\n",
      "Epoch 19/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.8290 - loss: 0.4859 - val_accuracy: 0.8405 - val_loss: 0.4729\n",
      "Epoch 20/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.8262 - loss: 0.4692 - val_accuracy: 0.8356 - val_loss: 0.4525\n",
      "Epoch 21/100\n",
      "102/102 - 5s - 47ms/step - accuracy: 0.8367 - loss: 0.4503 - val_accuracy: 0.8380 - val_loss: 0.4430\n",
      "Epoch 22/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.8416 - loss: 0.4409 - val_accuracy: 0.8368 - val_loss: 0.4338\n",
      "Epoch 23/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8443 - loss: 0.4269 - val_accuracy: 0.8479 - val_loss: 0.4100\n",
      "Epoch 24/100\n",
      "102/102 - 5s - 53ms/step - accuracy: 0.8520 - loss: 0.4101 - val_accuracy: 0.8503 - val_loss: 0.3999\n",
      "Epoch 25/100\n",
      "102/102 - 5s - 53ms/step - accuracy: 0.8502 - loss: 0.4041 - val_accuracy: 0.8552 - val_loss: 0.3906\n",
      "Epoch 26/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8526 - loss: 0.3992 - val_accuracy: 0.8528 - val_loss: 0.3837\n",
      "Epoch 27/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8551 - loss: 0.3893 - val_accuracy: 0.8613 - val_loss: 0.3813\n",
      "Epoch 28/100\n",
      "102/102 - 5s - 47ms/step - accuracy: 0.8615 - loss: 0.3839 - val_accuracy: 0.8638 - val_loss: 0.3727\n",
      "Epoch 29/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8591 - loss: 0.3773 - val_accuracy: 0.8589 - val_loss: 0.3665\n",
      "Epoch 30/100\n",
      "102/102 - 5s - 47ms/step - accuracy: 0.8671 - loss: 0.3659 - val_accuracy: 0.8601 - val_loss: 0.3617\n",
      "Epoch 31/100\n",
      "102/102 - 5s - 47ms/step - accuracy: 0.8707 - loss: 0.3625 - val_accuracy: 0.8626 - val_loss: 0.3641\n",
      "Epoch 32/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.8674 - loss: 0.3633 - val_accuracy: 0.8663 - val_loss: 0.3577\n",
      "Epoch 33/100\n",
      "102/102 - 5s - 53ms/step - accuracy: 0.8738 - loss: 0.3555 - val_accuracy: 0.8515 - val_loss: 0.3732\n",
      "Epoch 34/100\n",
      "102/102 - 6s - 54ms/step - accuracy: 0.8723 - loss: 0.3502 - val_accuracy: 0.8663 - val_loss: 0.3492\n",
      "Epoch 35/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8757 - loss: 0.3530 - val_accuracy: 0.8687 - val_loss: 0.3512\n",
      "Epoch 36/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8747 - loss: 0.3477 - val_accuracy: 0.8687 - val_loss: 0.3452\n",
      "Epoch 37/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 0.8775 - loss: 0.3422 - val_accuracy: 0.8712 - val_loss: 0.3397\n",
      "Epoch 38/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.8793 - loss: 0.3338 - val_accuracy: 0.8699 - val_loss: 0.3446\n",
      "Epoch 39/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8809 - loss: 0.3393 - val_accuracy: 0.8699 - val_loss: 0.3428\n",
      "Epoch 40/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8775 - loss: 0.3391 - val_accuracy: 0.8761 - val_loss: 0.3339\n",
      "Epoch 41/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8824 - loss: 0.3309 - val_accuracy: 0.8773 - val_loss: 0.3337\n",
      "Epoch 42/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.8833 - loss: 0.3328 - val_accuracy: 0.8650 - val_loss: 0.3462\n",
      "Epoch 43/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8806 - loss: 0.3260 - val_accuracy: 0.8748 - val_loss: 0.3309\n",
      "Epoch 44/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.8842 - loss: 0.3191 - val_accuracy: 0.8761 - val_loss: 0.3305\n",
      "Epoch 45/100\n",
      "102/102 - 5s - 53ms/step - accuracy: 0.8812 - loss: 0.3246 - val_accuracy: 0.8785 - val_loss: 0.3235\n",
      "Epoch 46/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 0.8861 - loss: 0.3163 - val_accuracy: 0.8810 - val_loss: 0.3198\n",
      "Epoch 47/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 0.8849 - loss: 0.3201 - val_accuracy: 0.8785 - val_loss: 0.3233\n",
      "Epoch 48/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8855 - loss: 0.3153 - val_accuracy: 0.8847 - val_loss: 0.3184\n",
      "Epoch 49/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8870 - loss: 0.3180 - val_accuracy: 0.8834 - val_loss: 0.3175\n",
      "Epoch 50/100\n",
      "102/102 - 5s - 53ms/step - accuracy: 0.8864 - loss: 0.3133 - val_accuracy: 0.8859 - val_loss: 0.3133\n",
      "Epoch 51/100\n",
      "102/102 - 6s - 58ms/step - accuracy: 0.8910 - loss: 0.3122 - val_accuracy: 0.8761 - val_loss: 0.3213\n",
      "Epoch 52/100\n",
      "102/102 - 5s - 54ms/step - accuracy: 0.8867 - loss: 0.3107 - val_accuracy: 0.8945 - val_loss: 0.3096\n",
      "Epoch 53/100\n",
      "102/102 - 6s - 56ms/step - accuracy: 0.8913 - loss: 0.3050 - val_accuracy: 0.8883 - val_loss: 0.3101\n",
      "Epoch 54/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 0.8861 - loss: 0.3099 - val_accuracy: 0.8908 - val_loss: 0.3105\n",
      "Epoch 55/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8904 - loss: 0.3036 - val_accuracy: 0.8810 - val_loss: 0.3132\n",
      "Epoch 56/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8916 - loss: 0.3024 - val_accuracy: 0.8822 - val_loss: 0.3118\n",
      "Epoch 57/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8938 - loss: 0.3046 - val_accuracy: 0.8896 - val_loss: 0.3079\n",
      "Epoch 58/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 0.8916 - loss: 0.2993 - val_accuracy: 0.8945 - val_loss: 0.3027\n",
      "Epoch 59/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8913 - loss: 0.2996 - val_accuracy: 0.8896 - val_loss: 0.3062\n",
      "Epoch 60/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8925 - loss: 0.3031 - val_accuracy: 0.8883 - val_loss: 0.3053\n",
      "Epoch 61/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8907 - loss: 0.2976 - val_accuracy: 0.8957 - val_loss: 0.3016\n",
      "Epoch 62/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 0.8919 - loss: 0.2958 - val_accuracy: 0.8847 - val_loss: 0.3065\n",
      "Epoch 63/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8944 - loss: 0.2955 - val_accuracy: 0.8994 - val_loss: 0.2995\n",
      "Epoch 64/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8922 - loss: 0.3006 - val_accuracy: 0.8957 - val_loss: 0.2967\n",
      "Epoch 65/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8947 - loss: 0.2936 - val_accuracy: 0.8982 - val_loss: 0.2975\n",
      "Epoch 66/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.8932 - loss: 0.2964 - val_accuracy: 0.8982 - val_loss: 0.2962\n",
      "Epoch 67/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.8984 - loss: 0.2896 - val_accuracy: 0.8994 - val_loss: 0.2966\n",
      "Epoch 68/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8944 - loss: 0.2911 - val_accuracy: 0.8945 - val_loss: 0.2965\n",
      "Epoch 69/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.8928 - loss: 0.2917 - val_accuracy: 0.8920 - val_loss: 0.2964\n",
      "Epoch 70/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8962 - loss: 0.2924 - val_accuracy: 0.8908 - val_loss: 0.2958\n",
      "Epoch 71/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.8941 - loss: 0.2875 - val_accuracy: 0.8982 - val_loss: 0.2916\n",
      "Epoch 72/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 0.8947 - loss: 0.2893 - val_accuracy: 0.8945 - val_loss: 0.2927\n",
      "Epoch 73/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 0.8956 - loss: 0.2866 - val_accuracy: 0.8847 - val_loss: 0.3007\n",
      "Epoch 74/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8993 - loss: 0.2814 - val_accuracy: 0.8957 - val_loss: 0.2908\n",
      "Epoch 75/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.8944 - loss: 0.2817 - val_accuracy: 0.8957 - val_loss: 0.2927\n",
      "Epoch 76/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 0.8941 - loss: 0.2847 - val_accuracy: 0.8896 - val_loss: 0.2930\n",
      "Epoch 77/100\n",
      "102/102 - 6s - 58ms/step - accuracy: 0.8950 - loss: 0.2822 - val_accuracy: 0.8896 - val_loss: 0.2911\n",
      "Epoch 78/100\n",
      "102/102 - 5s - 54ms/step - accuracy: 0.8944 - loss: 0.2813 - val_accuracy: 0.8957 - val_loss: 0.2892\n",
      "Epoch 79/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.8990 - loss: 0.2824 - val_accuracy: 0.8969 - val_loss: 0.2842\n",
      "Epoch 80/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 0.8968 - loss: 0.2778 - val_accuracy: 0.8957 - val_loss: 0.2880\n",
      "Epoch 81/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8996 - loss: 0.2796 - val_accuracy: 0.8945 - val_loss: 0.2880\n",
      "Epoch 82/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8984 - loss: 0.2801 - val_accuracy: 0.8957 - val_loss: 0.2821\n",
      "Epoch 83/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8978 - loss: 0.2762 - val_accuracy: 0.8933 - val_loss: 0.2838\n",
      "Epoch 84/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8965 - loss: 0.2799 - val_accuracy: 0.8871 - val_loss: 0.2926\n",
      "Epoch 85/100\n",
      "102/102 - 5s - 53ms/step - accuracy: 0.9018 - loss: 0.2773 - val_accuracy: 0.8920 - val_loss: 0.2844\n",
      "Epoch 86/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8993 - loss: 0.2734 - val_accuracy: 0.8920 - val_loss: 0.2846\n",
      "Epoch 87/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.8996 - loss: 0.2699 - val_accuracy: 0.8920 - val_loss: 0.2827\n",
      "Epoch 88/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.9011 - loss: 0.2753 - val_accuracy: 0.9006 - val_loss: 0.2767\n",
      "Epoch 89/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8990 - loss: 0.2723 - val_accuracy: 0.8994 - val_loss: 0.2765\n",
      "Epoch 90/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8993 - loss: 0.2728 - val_accuracy: 0.8920 - val_loss: 0.2810\n",
      "Epoch 91/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9011 - loss: 0.2709 - val_accuracy: 0.8920 - val_loss: 0.2795\n",
      "Epoch 92/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.8999 - loss: 0.2692 - val_accuracy: 0.8883 - val_loss: 0.2934\n",
      "Epoch 93/100\n",
      "102/102 - 5s - 50ms/step - accuracy: 0.9033 - loss: 0.2731 - val_accuracy: 0.8908 - val_loss: 0.2785\n",
      "Epoch 94/100\n",
      "102/102 - 5s - 48ms/step - accuracy: 0.9014 - loss: 0.2692 - val_accuracy: 0.8908 - val_loss: 0.2751\n",
      "Epoch 95/100\n",
      "102/102 - 5s - 52ms/step - accuracy: 0.8984 - loss: 0.2667 - val_accuracy: 0.8908 - val_loss: 0.2739\n",
      "Epoch 96/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9030 - loss: 0.2689 - val_accuracy: 0.8945 - val_loss: 0.2805\n",
      "Epoch 97/100\n",
      "102/102 - 5s - 51ms/step - accuracy: 0.9014 - loss: 0.2630 - val_accuracy: 0.8920 - val_loss: 0.2832\n",
      "Epoch 98/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.8993 - loss: 0.2627 - val_accuracy: 0.8957 - val_loss: 0.2776\n",
      "Epoch 99/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9054 - loss: 0.2659 - val_accuracy: 0.8945 - val_loss: 0.2777\n",
      "Epoch 100/100\n",
      "102/102 - 5s - 49ms/step - accuracy: 0.9088 - loss: 0.2601 - val_accuracy: 0.8933 - val_loss: 0.2765\n",
      "Test Accuracy for SGD Optimizer: 0.8933\n",
      "\n",
      "Running experiment: Larger Batch\n",
      "Epoch 1/100\n",
      "51/51 - 6s - 125ms/step - accuracy: 0.7989 - loss: 0.4380 - val_accuracy: 0.8859 - val_loss: 0.2950\n",
      "Epoch 2/100\n",
      "51/51 - 5s - 98ms/step - accuracy: 0.9036 - loss: 0.2640 - val_accuracy: 0.8982 - val_loss: 0.2531\n",
      "Epoch 3/100\n",
      "51/51 - 5s - 95ms/step - accuracy: 0.9229 - loss: 0.2144 - val_accuracy: 0.9313 - val_loss: 0.1773\n",
      "Epoch 4/100\n",
      "51/51 - 5s - 93ms/step - accuracy: 0.9361 - loss: 0.1777 - val_accuracy: 0.9227 - val_loss: 0.1985\n",
      "Epoch 5/100\n",
      "51/51 - 5s - 89ms/step - accuracy: 0.9481 - loss: 0.1482 - val_accuracy: 0.9460 - val_loss: 0.1403\n",
      "Epoch 6/100\n",
      "51/51 - 5s - 89ms/step - accuracy: 0.9533 - loss: 0.1222 - val_accuracy: 0.9460 - val_loss: 0.1386\n",
      "Epoch 7/100\n",
      "51/51 - 5s - 92ms/step - accuracy: 0.9601 - loss: 0.1035 - val_accuracy: 0.9558 - val_loss: 0.1345\n",
      "Epoch 8/100\n",
      "51/51 - 5s - 94ms/step - accuracy: 0.9687 - loss: 0.0907 - val_accuracy: 0.9583 - val_loss: 0.1203\n",
      "Epoch 9/100\n",
      "51/51 - 5s - 94ms/step - accuracy: 0.9767 - loss: 0.0752 - val_accuracy: 0.9472 - val_loss: 0.1484\n",
      "Epoch 10/100\n",
      "51/51 - 5s - 89ms/step - accuracy: 0.9751 - loss: 0.0741 - val_accuracy: 0.9730 - val_loss: 0.0995\n",
      "Epoch 11/100\n",
      "51/51 - 5s - 92ms/step - accuracy: 0.9819 - loss: 0.0593 - val_accuracy: 0.9656 - val_loss: 0.1075\n",
      "Epoch 12/100\n",
      "51/51 - 5s - 98ms/step - accuracy: 0.9859 - loss: 0.0441 - val_accuracy: 0.9669 - val_loss: 0.1094\n",
      "Epoch 13/100\n",
      "51/51 - 6s - 108ms/step - accuracy: 0.9816 - loss: 0.0563 - val_accuracy: 0.9521 - val_loss: 0.1488\n",
      "Epoch 14/100\n",
      "51/51 - 5s - 102ms/step - accuracy: 0.9831 - loss: 0.0553 - val_accuracy: 0.9656 - val_loss: 0.1157\n",
      "Epoch 15/100\n",
      "51/51 - 5s - 99ms/step - accuracy: 0.9886 - loss: 0.0310 - val_accuracy: 0.9730 - val_loss: 0.1225\n",
      "Epoch 16/100\n",
      "51/51 - 5s - 95ms/step - accuracy: 0.9917 - loss: 0.0284 - val_accuracy: 0.9755 - val_loss: 0.1348\n",
      "Epoch 17/100\n",
      "51/51 - 6s - 113ms/step - accuracy: 0.9846 - loss: 0.0472 - val_accuracy: 0.9706 - val_loss: 0.1300\n",
      "Epoch 18/100\n",
      "51/51 - 7s - 143ms/step - accuracy: 0.9908 - loss: 0.0292 - val_accuracy: 0.9681 - val_loss: 0.1132\n",
      "Epoch 19/100\n",
      "51/51 - 7s - 143ms/step - accuracy: 0.9963 - loss: 0.0165 - val_accuracy: 0.9730 - val_loss: 0.1416\n",
      "Epoch 20/100\n",
      "51/51 - 6s - 108ms/step - accuracy: 0.9969 - loss: 0.0143 - val_accuracy: 0.9644 - val_loss: 0.1504\n",
      "Epoch 21/100\n",
      "51/51 - 10432s - 205s/step - accuracy: 0.9929 - loss: 0.0265 - val_accuracy: 0.9718 - val_loss: 0.1232\n",
      "Epoch 22/100\n",
      "51/51 - 14s - 269ms/step - accuracy: 0.9920 - loss: 0.0245 - val_accuracy: 0.9656 - val_loss: 0.1710\n",
      "Epoch 23/100\n",
      "51/51 - 10s - 200ms/step - accuracy: 0.9908 - loss: 0.0245 - val_accuracy: 0.9656 - val_loss: 0.1313\n",
      "Epoch 24/100\n",
      "51/51 - 8s - 156ms/step - accuracy: 0.9929 - loss: 0.0180 - val_accuracy: 0.9706 - val_loss: 0.1761\n",
      "Epoch 25/100\n",
      "51/51 - 7s - 140ms/step - accuracy: 0.9856 - loss: 0.0366 - val_accuracy: 0.9718 - val_loss: 0.1556\n",
      "Epoch 26/100\n",
      "51/51 - 6s - 124ms/step - accuracy: 0.9960 - loss: 0.0132 - val_accuracy: 0.9472 - val_loss: 0.2600\n",
      "Epoch 27/100\n",
      "51/51 - 6s - 119ms/step - accuracy: 0.9939 - loss: 0.0179 - val_accuracy: 0.9742 - val_loss: 0.1688\n",
      "Epoch 28/100\n",
      "51/51 - 10s - 194ms/step - accuracy: 0.9982 - loss: 0.0069 - val_accuracy: 0.9706 - val_loss: 0.1768\n",
      "Epoch 29/100\n",
      "51/51 - 5s - 104ms/step - accuracy: 0.9994 - loss: 0.0034 - val_accuracy: 0.9620 - val_loss: 0.2663\n",
      "Epoch 30/100\n",
      "51/51 - 5s - 105ms/step - accuracy: 0.9945 - loss: 0.0114 - val_accuracy: 0.9742 - val_loss: 0.1723\n",
      "Epoch 31/100\n",
      "51/51 - 5s - 91ms/step - accuracy: 0.9936 - loss: 0.0190 - val_accuracy: 0.9791 - val_loss: 0.2146\n",
      "Epoch 32/100\n",
      "51/51 - 10s - 191ms/step - accuracy: 0.9920 - loss: 0.0256 - val_accuracy: 0.9706 - val_loss: 0.1527\n",
      "Epoch 33/100\n",
      "51/51 - 7s - 137ms/step - accuracy: 0.9985 - loss: 0.0073 - val_accuracy: 0.9742 - val_loss: 0.1838\n",
      "Epoch 34/100\n",
      "51/51 - 5s - 106ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9755 - val_loss: 0.2228\n",
      "Epoch 35/100\n",
      "51/51 - 5s - 98ms/step - accuracy: 0.9985 - loss: 0.0068 - val_accuracy: 0.9387 - val_loss: 0.3079\n",
      "Epoch 36/100\n",
      "51/51 - 5s - 93ms/step - accuracy: 0.9905 - loss: 0.0293 - val_accuracy: 0.9730 - val_loss: 0.1406\n",
      "Epoch 37/100\n",
      "51/51 - 5s - 104ms/step - accuracy: 0.9972 - loss: 0.0112 - val_accuracy: 0.9620 - val_loss: 0.2296\n",
      "Epoch 38/100\n",
      "51/51 - 5s - 103ms/step - accuracy: 0.9975 - loss: 0.0061 - val_accuracy: 0.9681 - val_loss: 0.1901\n",
      "Epoch 39/100\n",
      "51/51 - 7s - 141ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.9791 - val_loss: 0.2145\n",
      "Epoch 40/100\n",
      "51/51 - 12s - 233ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9742 - val_loss: 0.2144\n",
      "Epoch 41/100\n",
      "51/51 - 9s - 169ms/step - accuracy: 1.0000 - loss: 6.5801e-04 - val_accuracy: 0.9730 - val_loss: 0.2257\n",
      "Epoch 42/100\n",
      "51/51 - 10s - 194ms/step - accuracy: 1.0000 - loss: 4.5081e-04 - val_accuracy: 0.9755 - val_loss: 0.2335\n",
      "Epoch 43/100\n",
      "51/51 - 11s - 217ms/step - accuracy: 1.0000 - loss: 5.8498e-04 - val_accuracy: 0.9755 - val_loss: 0.2234\n",
      "Epoch 44/100\n",
      "51/51 - 7s - 141ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9779 - val_loss: 0.2687\n",
      "Epoch 45/100\n",
      "51/51 - 13s - 252ms/step - accuracy: 0.9991 - loss: 0.0022 - val_accuracy: 0.9767 - val_loss: 0.3054\n",
      "Epoch 46/100\n",
      "51/51 - 13s - 257ms/step - accuracy: 0.9917 - loss: 0.0248 - val_accuracy: 0.9546 - val_loss: 0.2100\n",
      "Epoch 47/100\n",
      "51/51 - 5s - 97ms/step - accuracy: 0.9920 - loss: 0.0235 - val_accuracy: 0.9706 - val_loss: 0.2120\n",
      "Epoch 48/100\n",
      "51/51 - 6s - 113ms/step - accuracy: 0.9972 - loss: 0.0087 - val_accuracy: 0.9706 - val_loss: 0.2066\n",
      "Epoch 49/100\n",
      "51/51 - 9s - 186ms/step - accuracy: 0.9988 - loss: 0.0056 - val_accuracy: 0.9669 - val_loss: 0.1855\n",
      "Epoch 50/100\n",
      "51/51 - 5s - 99ms/step - accuracy: 0.9991 - loss: 0.0026 - val_accuracy: 0.9742 - val_loss: 0.1941\n",
      "Epoch 51/100\n",
      "51/51 - 5s - 99ms/step - accuracy: 1.0000 - loss: 6.2438e-04 - val_accuracy: 0.9706 - val_loss: 0.2209\n",
      "Epoch 52/100\n",
      "51/51 - 5s - 99ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9779 - val_loss: 0.1886\n",
      "Epoch 53/100\n",
      "51/51 - 5s - 101ms/step - accuracy: 0.9979 - loss: 0.0060 - val_accuracy: 0.9681 - val_loss: 0.1989\n",
      "Epoch 54/100\n",
      "51/51 - 5s - 101ms/step - accuracy: 0.9951 - loss: 0.0133 - val_accuracy: 0.9681 - val_loss: 0.2371\n",
      "Epoch 55/100\n",
      "51/51 - 5s - 98ms/step - accuracy: 0.9939 - loss: 0.0156 - val_accuracy: 0.9718 - val_loss: 0.2192\n",
      "Epoch 56/100\n",
      "51/51 - 5s - 107ms/step - accuracy: 0.9997 - loss: 0.0027 - val_accuracy: 0.9681 - val_loss: 0.2222\n",
      "Epoch 57/100\n",
      "51/51 - 5s - 107ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.9644 - val_loss: 0.2438\n",
      "Epoch 58/100\n",
      "51/51 - 10s - 203ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9669 - val_loss: 0.2528\n",
      "Epoch 59/100\n",
      "51/51 - 6s - 119ms/step - accuracy: 0.9963 - loss: 0.0130 - val_accuracy: 0.9607 - val_loss: 0.2793\n",
      "Epoch 60/100\n",
      "51/51 - 6s - 113ms/step - accuracy: 0.9920 - loss: 0.0231 - val_accuracy: 0.9620 - val_loss: 0.2671\n",
      "Epoch 61/100\n",
      "51/51 - 6s - 115ms/step - accuracy: 0.9914 - loss: 0.0252 - val_accuracy: 0.9595 - val_loss: 0.2087\n",
      "Epoch 62/100\n",
      "51/51 - 6s - 122ms/step - accuracy: 0.9975 - loss: 0.0091 - val_accuracy: 0.9730 - val_loss: 0.2506\n",
      "Epoch 63/100\n",
      "51/51 - 6s - 109ms/step - accuracy: 0.9994 - loss: 0.0035 - val_accuracy: 0.9656 - val_loss: 0.2581\n",
      "Epoch 64/100\n",
      "51/51 - 7s - 130ms/step - accuracy: 1.0000 - loss: 8.2686e-04 - val_accuracy: 0.9693 - val_loss: 0.2584\n",
      "Epoch 65/100\n",
      "51/51 - 6s - 123ms/step - accuracy: 1.0000 - loss: 5.3817e-04 - val_accuracy: 0.9706 - val_loss: 0.2796\n",
      "Epoch 66/100\n",
      "51/51 - 6s - 120ms/step - accuracy: 1.0000 - loss: 4.8654e-04 - val_accuracy: 0.9706 - val_loss: 0.2896\n",
      "Epoch 67/100\n",
      "51/51 - 6s - 121ms/step - accuracy: 1.0000 - loss: 5.4840e-04 - val_accuracy: 0.9706 - val_loss: 0.2824\n",
      "Epoch 68/100\n",
      "51/51 - 12s - 245ms/step - accuracy: 0.9994 - loss: 0.0012 - val_accuracy: 0.9693 - val_loss: 0.2932\n",
      "Epoch 69/100\n",
      "51/51 - 7s - 129ms/step - accuracy: 0.9905 - loss: 0.0416 - val_accuracy: 0.9693 - val_loss: 0.1699\n",
      "Epoch 70/100\n",
      "51/51 - 6s - 119ms/step - accuracy: 0.9963 - loss: 0.0131 - val_accuracy: 0.9669 - val_loss: 0.1921\n",
      "Epoch 71/100\n",
      "51/51 - 13s - 257ms/step - accuracy: 0.9991 - loss: 0.0044 - val_accuracy: 0.9706 - val_loss: 0.1923\n",
      "Epoch 72/100\n",
      "51/51 - 16s - 316ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.9755 - val_loss: 0.2186\n",
      "Epoch 73/100\n",
      "51/51 - 8s - 162ms/step - accuracy: 0.9997 - loss: 7.0486e-04 - val_accuracy: 0.9706 - val_loss: 0.2275\n",
      "Epoch 74/100\n",
      "51/51 - 6s - 112ms/step - accuracy: 1.0000 - loss: 6.9558e-04 - val_accuracy: 0.9730 - val_loss: 0.2363\n",
      "Epoch 75/100\n",
      "51/51 - 6s - 115ms/step - accuracy: 1.0000 - loss: 4.4563e-04 - val_accuracy: 0.9706 - val_loss: 0.2490\n",
      "Epoch 76/100\n",
      "51/51 - 6s - 110ms/step - accuracy: 0.9994 - loss: 0.0016 - val_accuracy: 0.9706 - val_loss: 0.2522\n",
      "Epoch 77/100\n",
      "51/51 - 6s - 114ms/step - accuracy: 0.9997 - loss: 6.9692e-04 - val_accuracy: 0.9742 - val_loss: 0.2632\n",
      "Epoch 78/100\n",
      "51/51 - 5s - 108ms/step - accuracy: 1.0000 - loss: 3.7835e-04 - val_accuracy: 0.9706 - val_loss: 0.2633\n",
      "Epoch 79/100\n",
      "51/51 - 5s - 105ms/step - accuracy: 1.0000 - loss: 3.1881e-04 - val_accuracy: 0.9779 - val_loss: 0.2612\n",
      "Epoch 80/100\n",
      "51/51 - 6s - 109ms/step - accuracy: 1.0000 - loss: 2.5430e-04 - val_accuracy: 0.9730 - val_loss: 0.3026\n",
      "Epoch 81/100\n",
      "51/51 - 6s - 112ms/step - accuracy: 1.0000 - loss: 1.2205e-04 - val_accuracy: 0.9730 - val_loss: 0.2968\n",
      "Epoch 82/100\n",
      "51/51 - 6s - 114ms/step - accuracy: 1.0000 - loss: 2.7111e-04 - val_accuracy: 0.9706 - val_loss: 0.3084\n",
      "Epoch 83/100\n",
      "51/51 - 5s - 105ms/step - accuracy: 1.0000 - loss: 3.2966e-04 - val_accuracy: 0.9730 - val_loss: 0.2957\n",
      "Epoch 84/100\n",
      "51/51 - 6s - 109ms/step - accuracy: 1.0000 - loss: 2.5149e-04 - val_accuracy: 0.9693 - val_loss: 0.3249\n",
      "Epoch 85/100\n",
      "51/51 - 7s - 130ms/step - accuracy: 0.9880 - loss: 0.0365 - val_accuracy: 0.9411 - val_loss: 0.2219\n",
      "Epoch 86/100\n",
      "51/51 - 9s - 177ms/step - accuracy: 0.9905 - loss: 0.0294 - val_accuracy: 0.9509 - val_loss: 0.2313\n",
      "Epoch 87/100\n",
      "51/51 - 15s - 289ms/step - accuracy: 0.9923 - loss: 0.0229 - val_accuracy: 0.9791 - val_loss: 0.1866\n",
      "Epoch 88/100\n",
      "51/51 - 5s - 107ms/step - accuracy: 0.9960 - loss: 0.0119 - val_accuracy: 0.9644 - val_loss: 0.2186\n",
      "Epoch 89/100\n",
      "51/51 - 6s - 114ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9693 - val_loss: 0.2361\n",
      "Epoch 90/100\n",
      "51/51 - 6s - 112ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9706 - val_loss: 0.2565\n",
      "Epoch 91/100\n",
      "51/51 - 6s - 114ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9742 - val_loss: 0.2412\n",
      "Epoch 92/100\n",
      "51/51 - 6s - 114ms/step - accuracy: 0.9988 - loss: 0.0027 - val_accuracy: 0.9632 - val_loss: 0.2460\n",
      "Epoch 93/100\n",
      "51/51 - 9s - 170ms/step - accuracy: 0.9960 - loss: 0.0094 - val_accuracy: 0.9583 - val_loss: 0.2971\n",
      "Epoch 94/100\n",
      "51/51 - 7s - 137ms/step - accuracy: 0.9939 - loss: 0.0136 - val_accuracy: 0.9681 - val_loss: 0.2523\n",
      "Epoch 95/100\n",
      "51/51 - 6s - 110ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9632 - val_loss: 0.2855\n",
      "Epoch 96/100\n",
      "51/51 - 6s - 115ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9706 - val_loss: 0.3220\n",
      "Epoch 97/100\n",
      "51/51 - 5s - 107ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 0.9693 - val_loss: 0.3355\n",
      "Epoch 98/100\n",
      "51/51 - 5s - 107ms/step - accuracy: 0.9979 - loss: 0.0048 - val_accuracy: 0.9767 - val_loss: 0.3525\n",
      "Epoch 99/100\n",
      "51/51 - 6s - 114ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.9730 - val_loss: 0.3427\n",
      "Epoch 100/100\n",
      "51/51 - 6s - 115ms/step - accuracy: 1.0000 - loss: 4.9887e-04 - val_accuracy: 0.9681 - val_loss: 0.3995\n",
      "Test Accuracy for Larger Batch: 0.9681\n",
      "\n",
      "Summary of CNN Experiments:\n",
      "Baseline: 0.9742\n",
      "Low LR: 0.9620\n",
      "High LR: 0.9301\n",
      "SGD Optimizer: 0.8933\n",
      "Larger Batch: 0.9681\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter experiments\n",
    "experiments = [\n",
    "    {'name': 'Baseline', 'learning_rate': 0.001, 'optimizer': 'adam', 'batch_size': 32, 'final_activation': 'sigmoid'},\n",
    "    {'name': 'Low LR', 'learning_rate': 0.0001, 'optimizer': 'adam', 'batch_size': 32, 'final_activation': 'sigmoid'},\n",
    "    {'name': 'High LR', 'learning_rate': 0.01, 'optimizer': 'adam', 'batch_size': 32, 'final_activation': 'sigmoid'},\n",
    "    {'name': 'SGD Optimizer', 'learning_rate': 0.001, 'optimizer': 'sgd', 'batch_size': 32, 'final_activation': 'sigmoid'},\n",
    "    {'name': 'Larger Batch', 'learning_rate': 0.001, 'optimizer': 'adam', 'batch_size': 64, 'final_activation': 'sigmoid'}\n",
    "]\n",
    "\n",
    "results = {}\n",
    "num_epochs = 50  # For demonstration; increase epochs as needed\n",
    "\n",
    "for exp in experiments:\n",
    "    print(f\"\\nRunning experiment: {exp['name']}\")\n",
    "    model = build_cnn_model(learning_rate=exp['learning_rate'], optimizer_choice=exp['optimizer'], final_activation=exp['final_activation'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=exp['batch_size'], \n",
    "                        validation_data=(X_test, y_test), verbose=2)\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    results[exp['name']] = test_acc\n",
    "    print(f\"Test Accuracy for {exp['name']}: {test_acc:.4f}\")\n",
    "\n",
    "print(\"\\nSummary of CNN Experiments:\")\n",
    "for name, acc in results.items():\n",
    "    print(f\"{name}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparing CNN Performance with ML Classifiers\n",
    "\n",
    "In this section we extract handcrafted HOG features and train an SVM and a simple Neural Network (MLP) classifier. We then print classification reports for comparison.\n",
    "\n",
    "Note: Ensure that the image size used for the CNN (64x64) is consistent with the one used for handcrafted feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grayscale images: (4072, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "def load_images_grayscale(folder, label, image_size=(64, 64)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  \n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, image_size)\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Reload images in grayscale for handcrafted features\n",
    "mask_images_gray, mask_labels_gray = load_images_grayscale(mask_folder, label=1)\n",
    "no_mask_images_gray, no_mask_labels_gray = load_images_grayscale(no_mask_folder, label=0)\n",
    "\n",
    "X_gray = np.array(mask_images_gray + no_mask_images_gray)\n",
    "y_gray = np.array(mask_labels_gray + no_mask_labels_gray)\n",
    "\n",
    "print('Grayscale images:', X_gray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HOG features\n",
    "def extract_hog_features(images):\n",
    "    hog_features = []\n",
    "    for img in images:\n",
    "        features = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "        hog_features.append(features)\n",
    "    return np.array(hog_features)\n",
    "\n",
    "X_hog = extract_hog_features(X_gray)\n",
    "\n",
    "# Split for ML classifiers\n",
    "X_train_hog, X_test_hog, y_train_hog, y_test_hog = train_test_split(X_hog, y_gray, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       362\n",
      "           1       0.91      0.89      0.90       453\n",
      "\n",
      "    accuracy                           0.89       815\n",
      "   macro avg       0.88      0.89      0.88       815\n",
      "weighted avg       0.89      0.89      0.89       815\n",
      "\n",
      "Neural Network (MLP) Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       362\n",
      "           1       0.93      0.92      0.92       453\n",
      "\n",
      "    accuracy                           0.92       815\n",
      "   macro avg       0.91      0.92      0.92       815\n",
      "weighted avg       0.92      0.92      0.92       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SVM classifier\n",
    "svm_model = SVC(kernel='rbf',C=10)\n",
    "svm_model.fit(X_train_hog, y_train_hog)\n",
    "svm_pred = svm_model.predict(X_test_hog)\n",
    "print(\"SVM Classifier Report:\")\n",
    "print(classification_report(y_test_hog, svm_pred))\n",
    "\n",
    "# Train simple Neural Network classifier\n",
    "nn_model = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500)\n",
    "nn_model.fit(X_train_hog, y_train_hog)\n",
    "nn_pred = nn_model.predict(X_test_hog)\n",
    "print(\"Neural Network (MLP) Classifier Report:\")\n",
    "print(classification_report(y_test_hog, nn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook we:\n",
    "- Loaded and preprocessed the dataset.\n",
    "- Built and trained a CNN model with configurable hyperparameters.\n",
    "- Ran experiments with different hyperparameter settings and recorded test accuracies.\n",
    "- Compared the CNN's performance with ML classifiers using handcrafted HOG features.\n",
    "\n",
    "Feel free to modify hyperparameters and architecture to further improve the performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035bb8ac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
